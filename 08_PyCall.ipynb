{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyCall\n",
    "\n",
    "JuliaからPythonパッケージを利用するための仕組み\n",
    "\n",
    "### Setup\n",
    "\n",
    "#### Environment\n",
    "- OS: Ubuntu 18.04 LTS\n",
    "- Python: `3.7.3` (Miniconda `4.7.10`)\n",
    "    - Jupyter Notebook: `6.0.0`\n",
    "\n",
    "#### Installation\n",
    "少し古い情報を漁ると、REPLで `Pkg.add(\"PyCall\")` というコマンドを叩くと書いてあるが、Julia 1.0以降では、pkgモードでパッケージの追加を行う\n",
    "\n",
    "```bash\n",
    "# Julia REPL起動\n",
    "$ julia\n",
    "\n",
    "julia> # `]` と打って、pkgモードに移行\n",
    "\n",
    "# PyCallインストール\n",
    "(v1.1) pkg> add PyCall\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling PyCall [438e738f-606a-5dbb-bf0a-cddfbfd45ab0]\n",
      "└ @ Base loading.jl:1186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "v\"3.7.3\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyCallパッケージを使う\n",
    "using PyCall\n",
    "\n",
    "# Pythonバージョン確認\n",
    "PyCall.pyversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/user/miniconda3/bin/python3\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pythonのパスを確認\n",
    "PyCall.pyprogramname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/user/miniconda3/lib/libpython3.7m.so.1.0\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pythonライブラリのパスを確認\n",
    "PyCall.libpython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyCall経由でPyTorchを使う\n",
    "\n",
    "- **PyTorch**\n",
    "    - Python用のDeepLearningフレームワーク\n",
    "    - Define-by-Run（ニューラルネットワークを定義しながら実行できる）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefining constant Variable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject <module 'torch.nn.functional' from '/home/user/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pyimport torch\n",
    "const Variable = torch.autograd.Variable\n",
    "const nn = torch.nn\n",
    "const F = nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <class 'Net'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pydef mutable struct Net <: nn.Module\n",
    "\n",
    "    __init__(self) = begin\n",
    "        pybuiltin(:super)(Net, self)[:__init__]()\n",
    "        self[:conv1] = nn[:Conv2d](1, 6, 5)\n",
    "        self[:conv2] = nn[:Conv2d](6, 16, 5)\n",
    "        self[:fc1] = nn[:Linear](16 * 5 * 5, 120)\n",
    "        self[:fc2] = nn[:Linear](120, 84)\n",
    "        self[:fc3] = nn[:Linear](84, 10)\n",
    "    end\n",
    "\n",
    "    forward(self, x) = begin\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x =  F[:max_pool2d](F[:relu](self[:conv1](x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F[:max_pool2d](F[:relu](self[:conv2](x)), 2)\n",
    "        x = x[:view](-1, self[:num_flat_features](x))\n",
    "        x = F[:relu](self[:fc1](x))\n",
    "        x = F[:relu](self[:fc2](x))\n",
    "        x = self[:fc3](x)\n",
    "    end\n",
    "\n",
    "    num_flat_features(self, x) = begin\n",
    "        size = x[:size]()[2:end]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size\n",
    "            num_features *= s\n",
    "        end\n",
    "        return num_features\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyObject Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "10\n",
      "(6, 1, 5, 5)\n",
      "PyObject tensor([[-0.0502,  0.0667,  0.1353, -0.0927, -0.0093, -0.0398,  0.1152,  0.0757,\n",
      "         -0.1674, -0.0594]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "println(net)\n",
    "\n",
    "params = pybuiltin(:list)(net.parameters())\n",
    "println(length(params))\n",
    "println(params[1].size())  # conv1's .weight\n",
    "\n",
    "input = Variable(torch.randn(1, 1, 32, 32))\n",
    "out = net(input)\n",
    "println(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "PyCall.PyError",
     "evalue": "PyError ($(Expr(:escape, :(ccall(#= /home/user/.julia/packages/PyCall/ttONZ/src/pyfncall.jl:44 =# @pysym(:PyObject_Call), PyPtr, (PyPtr, PyPtr, PyPtr), o, pyargsptr, kw))))) <class 'RuntimeError'>\nRuntimeError(\"Expected object of scalar type Float but got scalar type Long for argument #2 'target'\")\n  File \"/home/user/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/user/miniconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\", line 443, in forward\n    return F.mse_loss(input, target, reduction=self.reduction)\n  File \"/home/user/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py\", line 2257, in mse_loss\n    ret = torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\n",
     "output_type": "error",
     "traceback": [
      "PyError ($(Expr(:escape, :(ccall(#= /home/user/.julia/packages/PyCall/ttONZ/src/pyfncall.jl:44 =# @pysym(:PyObject_Call), PyPtr, (PyPtr, PyPtr, PyPtr), o, pyargsptr, kw))))) <class 'RuntimeError'>\nRuntimeError(\"Expected object of scalar type Float but got scalar type Long for argument #2 'target'\")\n  File \"/home/user/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/user/miniconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\", line 443, in forward\n    return F.mse_loss(input, target, reduction=self.reduction)\n  File \"/home/user/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py\", line 2257, in mse_loss\n    ret = torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\n",
      "",
      "Stacktrace:",
      " [1] pyerr_check at /home/user/.julia/packages/PyCall/ttONZ/src/exception.jl:60 [inlined]",
      " [2] pyerr_check at /home/user/.julia/packages/PyCall/ttONZ/src/exception.jl:64 [inlined]",
      " [3] macro expansion at /home/user/.julia/packages/PyCall/ttONZ/src/exception.jl:84 [inlined]",
      " [4] __pycall!(::PyObject, ::Ptr{PyCall.PyObject_struct}, ::PyObject, ::Ptr{Nothing}) at /home/user/.julia/packages/PyCall/ttONZ/src/pyfncall.jl:44",
      " [5] _pycall!(::PyObject, ::PyObject, ::Tuple{PyObject,PyObject}, ::Int64, ::Ptr{Nothing}) at /home/user/.julia/packages/PyCall/ttONZ/src/pyfncall.jl:29",
      " [6] _pycall!(::PyObject, ::PyObject, ::Tuple{PyObject,PyObject}, ::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/user/.julia/packages/PyCall/ttONZ/src/pyfncall.jl:11",
      " [7] #call#111(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::PyObject, ::PyObject, ::Vararg{PyObject,N} where N) at /home/user/.julia/packages/PyCall/ttONZ/src/pyfncall.jl:89",
      " [8] (::PyObject)(::PyObject, ::Vararg{PyObject,N} where N) at /home/user/.julia/packages/PyCall/ttONZ/src/pyfncall.jl:89",
      " [9] top-level scope at In[34]:4"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = Variable(torch.arange(1, 11))  # a dummy target, for example\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "println(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(o::PyObject, s::Symbol)` is deprecated in favor of dot overloading (`getproperty`) so elements should now be accessed as e.g. `o.s` instead of `o[:s]`.\n",
      "│   caller = top-level scope at In[35]:1\n",
      "└ @ Core In[35]:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(o::PyObject, s::Symbol)` is deprecated in favor of dot overloading (`getproperty`) so elements should now be accessed as e.g. `o.s` instead of `o[:s]`.\n",
      "│   caller = top-level scope at In[35]:4\n",
      "└ @ Core In[35]:4\n",
      "┌ Warning: `getindex(o::PyObject, s::Symbol)` is deprecated in favor of dot overloading (`getproperty`) so elements should now be accessed as e.g. `o.s` instead of `o[:s]`.\n",
      "│   caller = top-level scope at In[35]:4\n",
      "└ @ Core In[35]:4\n",
      "┌ Warning: `getindex(o::PyObject, s::Symbol)` is deprecated in favor of dot overloading (`getproperty`) so elements should now be accessed as e.g. `o.s` instead of `o[:s]`.\n",
      "│   caller = top-level scope at In[35]:4\n",
      "└ @ Core In[35]:4\n"
     ]
    },
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: `nothing` should not be printed; use `show`, `repr`, or custom output instead.",
     "output_type": "error",
     "traceback": [
      "ArgumentError: `nothing` should not be printed; use `show`, `repr`, or custom output instead.",
      "",
      "Stacktrace:",
      " [1] print(::IJulia.IJuliaStdio{Base.PipeEndpoint}, ::Nothing) at ./show.jl:566",
      " [2] print(::IJulia.IJuliaStdio{Base.PipeEndpoint}, ::Nothing, ::Char) at ./strings/io.jl:42",
      " [3] println(::IJulia.IJuliaStdio{Base.PipeEndpoint}, ::Nothing) at ./strings/io.jl:69",
      " [4] println(::Nothing) at ./coreio.jl:4",
      " [5] top-level scope at In[35]:4"
     ]
    }
   ],
   "source": [
    "net[:zero_grad]()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "println(\"conv1.bias.grad before backward\")\n",
    "println(net[:conv1][:bias][:grad])\n",
    "\n",
    "loss[:backward]()\n",
    "\n",
    "println(\"conv1.bias.grad after backward\")\n",
    "println(net[:conv1][:bias][:grad])\n",
    "\n",
    "const optim = torch[:optim]\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim[:SGD](net[:parameters](), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer[:zero_grad]()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss[:backward]()\n",
    "optimizer[:step]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
